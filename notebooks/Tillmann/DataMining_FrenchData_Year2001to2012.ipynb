{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comments on what this notebook does:\n",
    "\n",
    "This notebook is used to process data from the French webpage. \n",
    "URL:  \n",
    "https://www.data.gouv.fr/fr/datasets/emissions-de-co2-et-de-polluants-des-vehicules-commercialises-en-france/#_\n",
    "\n",
    "The Excel files are downloaded and converted to CSV format, with _year.csv appended to the end of each file name. \n",
    "These files are stored in the project/data directory. Which will be ignored in the ./gitignore file. \n",
    "The following steps will prepare all csv into a common DataFrame which ranges from the year 2001 to 2014 and describes the registrations of cars in france and some \n",
    "of their technical specifications as well as their CO2 emission. \n",
    "\n",
    "# WARNING:\n",
    "\n",
    "For the script to work the data files must be positiong in the data path of the repository. \n",
    "Or the path to the data must be adapted accordingly. In this script all csv data must be in data_path \n",
    "\n",
    "\n",
    "# The process steps which will be done in here:**\n",
    "\n",
    " * Loading data \n",
    "     * deleting emtpy columns and empty rows\n",
    "     * delete indexes \n",
    "     * collecte column names in column_names list \n",
    "     * add additional year at each df_variable (global) \n",
    "\n",
    " * Working with specifica data \n",
    "     * replacing commas with points for floats \n",
    "     * delete double columns which contain redundant information \n",
    "\n",
    " * Combine all df to one list to work simultaneous one one list of dfs\n",
    "\n",
    " * Getting an overview of shape and column names \n",
    "\n",
    " * Mapping: Relabeling the column names into groups with common entries\n",
    " * Give clear english name \n",
    "\n",
    " * Combine all data frames into one big\n",
    "     * rename duplicate columns if there are still some \n",
    "     * combine into df named: data_all\n",
    "\n",
    " * Converting object type columns to flaots if possible \n",
    "\n",
    " * Filling empty entries with nans\n",
    "\n",
    " * Saving data frame all into a file called: 'data_all_french.csv'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all import the required libraries \n",
    "# Data and math  \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Visualisation \n",
    "import matplotlib.pyplot as plt  # für Matplotlib\n",
    "import seaborn as sns            # für Seaborn\n",
    "import plotly.express as px      # für Plotly Express\n",
    "#%matplotlib inline\n",
    "\n",
    "# Import System Libraries \n",
    "import warnings\n",
    "import os\n",
    "# Ignor all warnings, because there is a front problem with mach \n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Data, deleting empty entries, Save dfs in callable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5183, 14)\n",
      "(19477, 15)\n",
      "(138, 12)\n",
      "(7980, 14)\n",
      "(15375, 14)\n",
      "(15114, 12)\n",
      "(25319, 15)\n",
      "(8259, 13)\n",
      "(40052, 25)\n",
      "(37816, 16)\n",
      "(5919, 12)\n",
      "(5398, 13)\n"
     ]
    }
   ],
   "source": [
    "# Retrieving data \n",
    "\n",
    "# Path to the neighbouring data folder\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "# Reading all data and save them in global variables \n",
    "# Iterate through all files in the Data directory\n",
    "for filename in os.listdir(data_path):\n",
    "    # Check if the file is a .csv file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Create the full path to the file\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        \n",
    "        # Extract the last 4 digits of the filename (before the extension)\n",
    "        last_four_digits = filename[-8:-4]  # Assumption: There are always 4 digits before the file extension\n",
    "        \n",
    "        # Make the year variable \n",
    "        year = int(last_four_digits)\n",
    "\n",
    "        # Read the .csv file into a DataFrame\n",
    "        df = pd.read_csv(file_path, encoding='latin1', sep=';', index_col=None)\n",
    "\n",
    "        ### Deleting empty columns and rows for each df before saving it in a global variable \n",
    "        # Identify columns that contain only NaN values\n",
    "        nan_columns = df.columns[df.isna().all()].tolist()    \n",
    "        # Drop the columns with only NaN values\n",
    "        df.drop(columns=nan_columns, inplace=True)\n",
    "        # Delete all rows that are completely empty (i.e., contain only NaN values)\n",
    "        empty_rows = df[df.isna().all(axis=1)].index\n",
    "        df.drop(index=empty_rows, inplace=True)\n",
    "\n",
    "        # Deleting indexing for later better working\n",
    "        df.reset_index(drop=True)\n",
    "\n",
    "        # Looking at the columns and the shape \n",
    "        column_names = df.columns.tolist()\n",
    "        #print(\"Column names in df of year:\", year, \"\\n List:\", column_names)\n",
    "        print(df.shape)\n",
    "        # Add an additional year column to each df\n",
    "        df['YEAR'] = year\n",
    "\n",
    "        # Save the DataFrame under the desired name\n",
    "        globals()[f'df_french_{last_four_digits}'] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with specific dataframes from certain years, deleting redundant double columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working specifically with dfs analyse content \n",
    "\n",
    "# Settings output of terminal to max to be able to work with all the information \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Special treatment for some extra dfs\n",
    "# Replacing commas with periods in entries \n",
    "df_french_2011 = df_french_2011.replace(',', '.', regex=True)\n",
    "df_french_2012 = df_french_2012.replace(',', '.', regex=True)\n",
    "\n",
    "# Deleting double columns which contain redundant data \n",
    "df_french_2002 = df_french_2002.drop(df_french_2002.columns[4], axis=1)\n",
    "df_french_2009 = df_french_2009.drop(df_french_2009.columns[13], axis=1)\n",
    "df_french_2010 = df_french_2010.drop(df_french_2010.columns[13], axis=1)\n",
    "df_french_2011 = df_french_2011.drop(df_french_2011.columns[1], axis=1)\n",
    "df_french_2011 = df_french_2011.drop(df_french_2011.columns[3], axis=1)\n",
    "df_french_2011 = df_french_2011.drop(df_french_2011.columns[2], axis=1)\n",
    "\n",
    "\"\"\"\n",
    "print(df_french_2001.head(3))\n",
    "print(df_french_2002.head(3))\n",
    "print(df_french_2003.head(3))\n",
    "print(df_french_2004.head(3))\n",
    "print(df_french_2005.head(3))\n",
    "print(df_french_2006.head(3))\n",
    "print(df_french_2007.head(3))\n",
    "print(df_french_2008.head(3))\n",
    "print(df_french_2009.head(3))\n",
    "print(df_french_2010.head(3))\n",
    "print(df_french_2011.head(3))\n",
    "print(df_french_2012.head(3))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_french_2001, column names: ['MARQUES', 'MODELE', 'TYP. MINES', 'CNIT', 'CARB', 'CV', 'PUISS.', 'BV', 'Urbain', 'Ex.Urb', 'Mixte', 'CO2', 'YEAR']\n",
      "\n",
      "df_french_2002, column names: ['MARQUE', 'MODELE VERSION', 'CNIT', 'Unnamed: 4', 'MINE', 'ENERGIE', 'puissance fiscale', 'puissance reelle', 'bv', 'urb', 'ex-urb', 'mixte', 'CO2', 'YEAR']\n",
      "\n",
      "df_french_2003, column names: ['MARQUE', 'MODELE VERSION', 'CNIT', 'MINE', 'ENERGIE', 'puissance fiscale', 'puissance reelle', 'bv', 'urb', 'ex-urb', 'mixte', 'CO2', 'IMMAT', 'YEAR']\n",
      "\n",
      "df_french_2004, column names: ['Marques', 'ModÃ¨les, Versions', 'CNIT', 'CARBURANT', 'Puiss Administrative', 'Puissance max', 'BV', 'Conso urb', 'Conso ex-urb', 'Conso mixte', 'CO2', 'Unnamed: 11', 'YEAR']\n",
      "\n",
      "df_french_2005, column names: ['MARQUE', 'MODELE VERSION', 'CNIT', 'puissance fiscale', 'puissance reelle', 'bv', 'urb', 'ex-urb', 'mixte', 'CO2', 'ENERGIE', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'YEAR']\n",
      "\n",
      "df_french_2006, column names: ['MARQUES', 'MODELE', 'TYP. MINES', 'CINT', 'CARB', 'CV', 'PUISS.', 'BV', 'Urbain', 'Ex.Urb', 'Mixte', 'CO2', 'Unnamed: 12', 'YEAR']\n",
      "\n",
      "df_french_2007, column names: ['MARQUE', 'MODELE VERSION', 'CNIT', 'puissance fiscale', 'puissance reelle', 'bv', 'urb', 'ex-urb', 'mixte', 'CO2', 'carburant', 'ETIQUETTE ENERGIE', 'YEAR']\n",
      "\n",
      "df_french_2008, column names: ['MARQUE', 'MODELE VERSION', 'CNIT', 'puissance fiscale', 'puissance reelle', 'bv', 'urb', 'ex-urb', 'mixte', 'CO2', 'carburant', 'ETIQUETTE ENERGIE', 'BONUS(-)/MALUS( )', 'TYPE 2', 'YEAR']\n",
      "\n",
      "df_french_2009, column names: ['MARQUE', 'MODELE VERSION', 'CNIT', 'puissance fiscale', 'puissance reelle', 'bv', 'urb', 'ex-urb', 'mixte', 'CO2', 'carburant', 'ETIQUETTE ENERGIE', 'BONUS(-)/MALUS(+)', 'Unnamed: 14', 'YEAR']\n",
      "\n",
      "df_french_2010, column names: ['MARQUE', 'MODELE VERSION', 'CNIT', 'puissance fiscale', 'puissance reelle', 'bv', 'urb', 'ex-urb', 'mixte', 'CO2', 'carburant', 'ETIQUETTE ENERGIE', 'BONUS(-)/MALUS(+)', 'Unnamed: 14', 'YEAR']\n",
      "\n",
      "df_french_2011, column names: ['MARQUES', 'lib_mod', 'tvv', 'typ_cbr', 'puiss_admin_98', 'puiss_max', 'typ_boite_nb_rapp', 'conso_urb', 'conso_exurb', 'conso_mixte', 'co2', 'champ_v9', 'date_maj', 'YEAR']\n",
      "\n",
      "df_french_2012, column names: ['lib_mrq', 'lib_mod_doss', 'lib_mod', 'dscom', 'cnit', 'tvv', 'typ_cbr', 'hybride', 'puiss_admin_98', 'puiss_max', 'typ_boite_nb_rapp', 'conso_urb', 'conso_exurb', 'conso_mixte', 'co2', 'co_typ_1', 'hc', 'nox', 'hcnox', 'ptcl', 'masse_ordma_min', 'masse_ordma_max', 'champ_v9', 'Carrosserie', 'gamme', 'YEAR']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine all df to one list to work simultaneous one one list of dfs \n",
    "dataframes = [\n",
    "    df_french_2001,\n",
    "    df_french_2002,\n",
    "    df_french_2003,\n",
    "    df_french_2004,\n",
    "    df_french_2005,\n",
    "    df_french_2006,\n",
    "    df_french_2007,\n",
    "    df_french_2008,\n",
    "    df_french_2009,\n",
    "    df_french_2010,\n",
    "    df_french_2011,\n",
    "    df_french_2012\n",
    "]\n",
    "\n",
    "# Corresponding names for the DataFrames\n",
    "df_names = [\n",
    "    'df_french_2001',\n",
    "    'df_french_2002',\n",
    "    'df_french_2003',\n",
    "    'df_french_2004',\n",
    "    'df_french_2005',\n",
    "    'df_french_2006',\n",
    "    'df_french_2007',\n",
    "    'df_french_2008',\n",
    "    'df_french_2009',\n",
    "    'df_french_2010',\n",
    "    'df_french_2011',\n",
    "    'df_french_2012'\n",
    "]\n",
    "\n",
    "# Iterate through each DataFrame and print its column names\n",
    "for df, name in zip(dataframes, df_names):\n",
    "    print(f\"{name}, column names: {list(df.columns)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get overview over column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an overview over all the df \n",
    "\n",
    "# Print out the shape and column names of all DataFrames at the end\n",
    "print(\"Final shapes and column names of all DataFrames:\")\n",
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"DataFrame {i + 1}:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Column names: {df.columns.tolist()}\\n\")\n",
    "\n",
    "# We should be able to make 12 overlay columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping of column names, combine all different to one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the relabeling of different column names to one will happen \n",
    "# The relabeling from french to a commong english collum name \n",
    "# Additional information on what the column names mean \n",
    "\n",
    "# Mapping\n",
    "\n",
    "column_mapping = {\n",
    "    # The manufacturer or brand of the vehicle (e.g., Opel, Ford).\n",
    "    'Brand': ['MARQUE', 'MARQUES', 'lib_mrq', 'Marques'],  \n",
    "    # The specific model or version of the vehicle (e.g., Corsa, Fiesta).\n",
    "    'Model': ['MODELE VERSION', 'MODELE_VERSION', 'MODELE', 'Modèles, Versions', 'lib_mod', 'ModÃ¨les, Versions', 'lib_mod_doss'],  \n",
    "    # Vehicle's technical type approval or classification. (e.g., MJD1102J)\n",
    "    'Type Mines': ['TYP. MINES', 'TYPE 2', 'TYPE', 'MINE', 'tvv'],\n",
    "    # The National Type Identification Code, unique to a vehicle in some countries. (e.g., M10ALFVP000M091)\n",
    "    'CNIT': ['CNIT', 'cnit'],\n",
    "    # The type of fuel the vehicle uses (e.g., ES, EL, GO)\n",
    "    'Fuel Type': ['ENERGIE', 'carburant',  'typ_cbr', 'CARBURANT', 'CARB'],  \n",
    "    # The actual power output of the engine, measured in horsepower or kilowatts. (e.g., 45.0, 77.0)\n",
    "    'Engine Power': ['PUISSANCE', 'puissance reelle',  'puiss_max', 'PUISS.'],  \n",
    "    # Fiscal horsepower, often used to calculate taxes on vehicles. (e.g., 4, 7)\n",
    "    'Fiscal Power': ['Puiss Administrative', 'puissance fiscale'],\n",
    "    # The type of transmission (e.g., M 5, V 0, A 6). \n",
    "    # A, M and V stand for different transmissions \n",
    "    'Transmission': ['bv', 'BV', 'typ_boite_nb_rapp'], \n",
    "    # Fuel consumption in urban or city driving conditions. (e.g., 11.3, 6.4)\n",
    "    'Urban Consumption': ['urb', 'Urbain', 'conso_urb', 'Conso urb', 'URBAIN'], \n",
    "    # Fuel consumption in extra-urban (highway or countryside) driving conditions.(e.g., 11.3, 6.4)\n",
    "    'Extra Urban Consumption': ['ex-urb', 'Ex.Urb', 'conso_exurb', 'Conso ex-urb', 'EX_URBAIN'],  \n",
    "    # Combined or average fuel consumption across different driving conditions. (e.g., 11.3, 6.4)\n",
    "    'Combined Consumption': ['mixte', 'Mixte', 'conso_mixte', 'Conso mixte', 'MIXTE'], \n",
    "    #The amount of CO2 the vehicle emits, usually measured in grams per kilometer (g/km).(e.g., 136.0, 196)\n",
    "    'CO2 Emissions': ['CO2', 'co2'], \n",
    "    # The admission year of the car. (e.g., 2001, 2012)\n",
    "    'YEAR': ['YEAR'],  \n",
    "    # Energy efficiency label, indicating the environmental rating of the vehicle. (e.g., A, B, C, E) \n",
    "    'Energy Label': ['ENERGIE', 'ETIQUETTE ENERGIE'], \n",
    "    # A government incentive (bonus) or penalty (malus) based on the vehicle's emissions. (e.g., -5000) \n",
    "    'Bonus/Malus': ['BONUS(-)/MALUS( )', 'BONUS(-)/MALUS(+)'],\n",
    "    # Likely refers to a technical or legal classification in the vehicle's registration data. (e.g., 70/220*2003/76EURO4)\n",
    "    'V9 Field': ['champ_v9', 'CHAMP_V9'],\n",
    "    # Body type of the car e.g., BERLINE\n",
    "    'Body Type': ['Carrosserie', 'CARROSSERIE'],  \n",
    "    # The vehicle's registration date. (e.g. Mar-03)\n",
    "    'Registration': ['IMMAT', 'date_maj', 'DATE_MAJ'],\n",
    "\n",
    "    # Unnamed columns \n",
    "    'Unnamed': ['Unnamed: 4', 'Unnamed: 5', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17'],\n",
    "}\n",
    "\n",
    "\n",
    "# Create a dictionary for column name mapping\n",
    "flattened_dict = {}\n",
    "\n",
    "# Flatten the column mapping into a single dictionary for renaming\n",
    "for key, values in column_mapping.items():\n",
    "    for value in values:\n",
    "        flattened_dict[value] = key\n",
    "\n",
    "# Print the flattened dictionary to check the final column mappings\n",
    "print(flattened_dict)\n",
    "\n",
    "# Iterate through all DataFrames and rename columns according to the mapping\n",
    "for df in dataframes:\n",
    "    # Rename the columns based on the flattened dictionary\n",
    "    df.rename(columns=flattened_dict, inplace=True)\n",
    "\n",
    "# Optional: Print the new column names for each DataFrame\n",
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"New column names for DataFrame {i + 1}: {df.columns}\\n\")\n",
    "    print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating all DFs to one big df of all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The combination of all data into one data_all data frame \n",
    "\n",
    "# Delete duplicate columns \n",
    "def deduplicate_columns(df):\n",
    "    \"\"\"Deduplicate DataFrame columns by appending a suffix.\"\"\"\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values.tolist()] = [f\"{dup}.{i+1}\" if i > 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "# Deduplicate column names\n",
    "dataframes = [deduplicate_columns(df) for df in dataframes]\n",
    "\n",
    "data_all = pd.concat(dataframes, axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert column dtypes to numeric of possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object type columns to flaots if possible \n",
    "\n",
    "# Information on total df \n",
    "print(data_all.shape)\n",
    "print(data_all.info())\n",
    "\n",
    "# Assuming 'data_all' is your DataFrame\n",
    "columns_to_convert = ['CV', 'Engine Power', 'Urban Consumption', 'Extra Urban Consumption', 'Combined Consumption', 'CO2 Emissions', 'Fiscal Power']\n",
    "\n",
    "# Convert columns to float, using pd.to_numeric to handle non-numeric values\n",
    "for col in columns_to_convert:\n",
    "    data_all[col] = pd.to_numeric(data_all[col], errors='coerce')\n",
    "\n",
    "# Check the data_all after conversion\n",
    "print(data_all[columns_to_convert].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling empty entries with nans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling empty entries with nans \n",
    "\n",
    "# Assuming 'data_all' is your DataFrame\n",
    "# Fill empty entries (None or empty strings) with NaN\n",
    "data_all.replace('', np.nan, inplace=True)  # Replace empty strings with NaN\n",
    "data_all.replace({None: np.nan}, inplace=True)  # Replace None with NaN (if any)\n",
    "\n",
    "# Check the DataFrame to see the changes\n",
    "print(data_all.isnull().sum())  # Show the count of NaNs in each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving df to data folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the filtered data in one df in the data folder \n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "data_path\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "output_file_path = data_path + '/data_all_french.csv'\n",
    "\n",
    "print(data_path)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "data_all.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Combined DataFrame saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_DS_CO2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
